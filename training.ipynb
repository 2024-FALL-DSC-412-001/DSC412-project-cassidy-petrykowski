{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv into dataframe\n",
    "data = pd.read_csv(\"data/patterns.csv\")\n",
    "\n",
    "data.shape\n",
    "\n",
    "# take the sizes of the images\n",
    "\n",
    "# get the average image size\n",
    "\n",
    "# f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Split the data between training and testing\n",
    "\n",
    "Because the csv contains the names for both the photos and grid, it can be split into one training set and one testing set.\n",
    "\n",
    "When the data is actually accessed, the distinction between inputs and outputs or photos and grids will be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7092f1985d\n",
      "4   5132dd96c5\n",
      "41  0d050bf92e\n",
      "27  af907f8935\n",
      "47  8c666944f5\n",
      "46  886db6af91\n",
      "52  390799fc65\n",
      "15  e4be6d77a7\n",
      "9   acce94a413\n",
      "16  63121aa4a0\n",
      "24  fd54ee1b2c\n",
      "31  53c2326730\n",
      "53  7c57adc9ee\n",
      "48  6db02c2311\n",
      "25  5052804e8a\n",
      "11  26f49e067d\n",
      "32  fcc5c0d75a\n",
      "49  dd5bdcacc3\n",
      "37  b7ac41ca29\n",
      "29  421a6d5da2\n",
      "40  9753694656\n",
      "1   ce2979431f\n",
      "21  cf9664fe4c\n",
      "2   4a00a86122\n",
      "43  edba2a6bbe\n",
      "39  09dbfb528d\n",
      "35  51684b0d4c\n",
      "23  c3cbf850c5\n",
      "45  b1b55738b1\n",
      "10  2666e3c94b\n",
      "22  ef642b8b75\n",
      "18  c3af8775ca\n",
      "55  f9232fe1b3\n",
      "20  95fa1a221a\n",
      "7   113fbb67d4\n",
      "42  2e024bf09e\n",
      "14  1e1bdfb2e7\n",
      "28  df03231a62\n",
      "51  337c0070cc\n",
      "38  7ce54e685d\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(             data,\n",
    "                                                    test_size=0.7, \n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "print(train_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
